{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS187\n",
    "## Lab 1-3 – Naive Bayes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n",
    "\n",
    "* `math.log2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation – Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# Otter grader which we use for grading does not support\n",
    "# !command, so we need to use shell(command) instead\n",
    "# to run shell commands\n",
    "def shell(str):\n",
    "    file = os.popen(str)\n",
    "    result = file.read()\n",
    "    print (result)\n",
    "    if file.close () is not None:\n",
    "        print ('failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Federalist data from the json file\n",
    "shell('wget -nv -N -P data https://github.com/nlp-course/data/raw/master/Federalist/federalist_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/federalist_data.json', 'r') as fin:\n",
    "    dataset = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, we extract the papers by either of Madison and Hamilton to serve as training data.\n",
    "training = list(filter(lambda ex: ex['authors'] in ['Madison', 'Hamilton'],\n",
    "                       dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Naive Bayes method reviewed\n",
    "$$\n",
    "   \\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "   \\newcommand{\\Prob}{{\\Pr}}\n",
    "   \\newcommand{\\given}{\\,|\\,}\n",
    "   \\newcommand{\\vect}[1]{\\mathbf{#1}}\n",
    "   \\newcommand{\\cnt}[1]{\\sharp(#1)}\n",
    "$$\n",
    "A quick review of the Naive Bayes (NB) method for text classification: In classification tasks, we're given a representation of some text as a vector $\\mathbf{x} = \\langle x_1, x_2, \\ldots, x_m \\rangle$ of feature values, and we'd like to determine which of a set of classes $\\{ c_1, c_2, \\ldots, c_k \\}$ the text should be classified as. \n",
    "\n",
    "> In the case at hand, the Federalist Papers, for a given document, we'll take $\\mathbf{x} = \\langle x_1, x_2, \\ldots, x_m \\rangle$ to be the sequence of words in the document, so each $x_i$ corresponds to a single word token.\n",
    "\n",
    "We might naturally think to choose that class that has the highest probability of being correct, that is, the class $c_i$ that maximizes $Pr(c_i \\mid \\mathbf{x})$.\n",
    "\n",
    "By Bayes rule (this is the \"Bayes\" part in the name \"Naive Bayes\"), \n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\argmax{i} \\Prob(c_i \\given \\vect{x}) \n",
    "&= \\argmax{i} \\frac{\\Prob(\\vect{x} \\given c_i) \\cdot \\Prob(c_i)}{\\Prob(\\vect{x})} \\\\\n",
    "&= \\argmax{i} \\Prob(\\vect{x} \\given c_i) \\cdot \\Prob(c_i)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question**: Why can we drop the denominator in the last step of this derivation?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "We use the following terminology: $\\Prob(c_i)$ is the _prior probability_. $\\Prob(\\vect{x} \\given c_i)$ is the _likelihood_. \n",
    "$\\Prob(c_i \\given \\vect{x})$ is the _posterior probability_.\n",
    "\n",
    "By the chain rule, \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Prob(\\vect{x} \\given c_i) &= \\Prob(x_1, \\ldots, x_m \\given c_i) \\\\\n",
    "&= \\Prob(x_1 \\given c_i) \\cdot \\Prob(x_2, \\ldots, x_m \\given x_1, c_i) \\\\\n",
    "&= \\Prob(x_1 \\given c_i) \\cdot \\Prob(x_2 \\given x_1, c_i) \\cdot \\Prob(x_3, \\ldots,\n",
    "x_m \\given x_1, x_2, c_i) \\\\\n",
    "\\cdots &= \\prod_{j=1}^m \\Prob(x_j \\given x_1, \\ldots, x_{j-1}, c_i)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We further assume that each feature $x_i$ is independent of all the others given the class. (That's the \"naive\" part.) So \n",
    "\n",
    "$$\n",
    "\\Prob(x_j \\given x_1, \\ldots, x_{j-1}, c_i) \\approx \\Prob(x_j \\given c_i)\n",
    "$$\n",
    "\n",
    "Using this approximation, we'll calculate instead the class as per the following maximization:\n",
    "\n",
    "$$\n",
    "\\argmax{i} \\Prob(c_i \\given \\vect{x}) \\approx \\argmax{i} \\Prob(c_i) \\cdot \\prod_{j=1}^m \\Prob(x_j \\given c_i)\n",
    "$$\n",
    "\n",
    "> This independence assumption, in the text, case, amounts to ignoring the order and even the cooccurence of words in a document, a quite aggressive and unrealistic independence assumption indeed.\n",
    "\n",
    "All we need, then, for the Naive Bayes classification method is values for $\\Prob(c_i)$ and $\\Prob(x_j \\given c_i)$ for each feature $x_j$ and each class $c_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes for the Federalist papers\n",
    "\n",
    "In applying Naive Bayes to an example in the Federalist dataset, we'll take the $x_i$ to be the _tokens in the example_. To make the calculations easier, in this lab, we won't use _all_ of the tokens, just the tokens of the four word types we've been attending to, but in an actual application of NB, we'd use all of the word types. As a reminder,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['on', 'upon', 'there', 'whilst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the two class labels are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Hamilton', 'Madison']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the prior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's start with the prior probabilities $\\Prob(c_i)$. In our case, there are only two class labels, for Hamilton and Madison. We estimate the probability of a class $c_i$ by simply counting the proportion of examples that are labeled with that class. (This estimate is the _sample probability_, which is also referred to as the _maximum likelihood estimate_ for reasons we'll skip for the moment.) That is, we estimate \n",
    "\n",
    "$$ \\Prob(c_i) \\approx \\frac{\\cnt{c_i}}{N} $$\n",
    "\n",
    "where $N$ is the number of training examples, and $\\cnt{c_i}$ is the number of training examples of class $c_i$.\n",
    "\n",
    "In the cell below, write code to count how many of the training examples are labeled with Hamilton and how many are labeled with Madison. Use these to provide estimates of the Hamilton and Madison prior probabilities.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: priors\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - calculate the prior probability for Madison\n",
    "prior_madison = ...\n",
    "prior_hamilton = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"priors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Madison  prior: {prior_madison:4f}\\n\"\n",
    "      f\"Hamilton prior: {prior_hamilton:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** What do these probabilities tell us about how we might predict the class of a document _prior_ to looking at the actual content of the document? (That's why these probabilities are called \"priors\".)\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_2\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Estimating the likelihood probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the likelihood probabilities, the conditional probability of a word given a class. For each likelihood $\\Prob(x_j \\given c_i)$, we need to estimate a value. We'll do so by simply counting the number of training examples with feature value $x_j$ that are labeled $c_i$ (notated as $\\cnt{x_j, c_i}$) as a proportion of the overall number of $c_i$ examples, that is,\n",
    "\n",
    "$$ \\Prob(x_j \\given c_i) \\approx \\frac{\\cnt{x_j, c_i}}{\\sum_k \\cnt{x_k, c_i}} $$\n",
    "\n",
    "Again, for the text case, each token counts as an instance of the corresponding word type in a training example.\n",
    " \n",
    "We've provided a small table that shows, for each label (author) and each of the four word types of interest, how many tokens of the type occurred in training examples with that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(dataset, label, index):\n",
    "    \"\"\"Returns the total count for `index` for examples with the \n",
    "       given `label`\"\"\"\n",
    "    return sum([example['counts'][index] \n",
    "                for example in dataset \n",
    "                if example['authors'] == label])\n",
    "\n",
    "# print a table header\n",
    "print(f\"{'':10}\", end=\"\")\n",
    "for i in range(4):\n",
    "    print(f\"{keywords[i]:>8}\", end=\"\")\n",
    "print()\n",
    "# print table entries for each label\n",
    "for label in classes:\n",
    "    print(f\"{label:10}\", end=\"\")\n",
    "    for i in range(4):\n",
    "        print(f\"{counts(training, label, i):8}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Given the counts in this table, what would an estimate be for the probability that a given word would be \"whilst\" given that the document was authored by Madison, that is, $\\Prob(\\mathrm{whilst} \\given \\mathrm{Madison})$?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: prob_whilst_madison\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "prob_whilst_madison = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"prob_whilst_madison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What about the probability $\\Prob(on \\given Hamilton)$?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: prob_on_hamilton\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "prob_on_hamilton = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"prob_on_hamilton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Consider a text \n",
    "\n",
    "> **whilst** depending neither **on** the American government nor **on** the British\n",
    "\n",
    "What would the Naive Bayes method estimate for the likelihood probability that this sentence was labeled as Hamilton? As Madison? (You will of course ignore all the words except for the four keywords in our little example. (We've boldfaced their occurrences.) With a full-blown NB analysis, we'd be using *all* of the words in the text.)\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: likelihoods\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "likelihood_hamilton = ...\n",
    "likelihood_madison = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"likelihoods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Madison  likelihood: {likelihood_madison:4f}\\n\"\n",
    "      f\"Hamilton likelihood: {likelihood_hamilton:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We're almost there. We simply need to combine the prior probabilities and the likelihood probabilities for each class to form the posterior, and select the largest one. (We don't actually calculate the posterior _probability_ because we aren't dividing through by $\\Prob(\\vect{x})$, but that doesn't matter because it's the same for both classes. Instead, we get something like a posterior _score_.)\n",
    "\n",
    "Calculate the posteriors for the two classes, and then specify which class – Hamilton or Madison – the NB method would predict for the sample text.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: posteriors\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "posterior_madison = ...\n",
    "posterior_hamilton = ...\n",
    "sample_classification = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"posteriors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Madison  posterior: {posterior_madison:4f}\\n\"\n",
    "      f\"Hamilton posterior: {posterior_hamilton:4f}\\n\"\n",
    "      f\"Sample classification: {sample_classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Is the NB-predicted classification the same as or different from the classification based on the priors? Why?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_3\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### A practical issue\n",
    "\n",
    "The computations of what we've been calling the posterior scores\n",
    "$$\\Prob(c_i \\given \\vect{x}) \\approx \\Prob(c_i) \\cdot \\prod_{j=1}^m \\Prob(x_j \\given c_i)$$\n",
    "involve the multiplication of many extremely small numbers. This is a recipe for computer underflow, leading to garbage outputs.\n",
    "\n",
    "Instead, rather than maximizing the posterior, we maximize its logarithm. Since the logarithm function is monotonic, whichever $i$ maximizes the posterior maximizes its log as well. And the log of the posterior is\n",
    "$$\\log \\left(\\Prob(c_i) \\cdot \\prod_{j=1}^m \\Prob(x_j \\given c_i)\\right)\n",
    "      = \\log\\Prob(c_i) + \\sum_{j=1}^m \\log\\Prob(x_j \\given c_i)$$\n",
    "so that the calculation now involves the sum of a bunch of numbers rather than the product. In practice, this computation is much more robust.\n",
    "\n",
    "> A log-of-probability value is referred to, colloquially if not quite accurately, as a _logit_, because of a resemblance to the values of [the logit function](https://en.wikipedia.org/wiki/Logit).\n",
    "\n",
    "Calculate the log of the posterior for Madison by summing up all of the pertinent parts, and similarly for Hamilton. Use the base 2 logarithm.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: log_posteriors\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - calculate the log of the posterior for Madison by summing up all of the pertinent parts\n",
    "log_posterior_madison = ...\n",
    "log_posterior_hamilton = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"log_posteriors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Madison  log posterior: {log_posterior_madison:4f}\\n\"\n",
    "      f\"Hamilton log posterior: {log_posterior_hamilton:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Which one of the two is larger? Does this accord with your expectation?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_4\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# End of lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
